{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of correlation between centroid offset and $\\Sigma_{10, \\rm flux\\ selected}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author(s):** Muhammad Jobair Hasan, Anowar J. Shajib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty propagation and the Pearson correlation coeffient (PCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the centroids (`\"center_x_light\"`, `\"center_x_mass\"`, `\"center_y_light\"`, `\"center_y_mass\"`) conform to Gaussian distributions of means equaling the corresponding medians and the standard deviations equaling the corresponding averages (of the upper and the lower) $1\\sigma$ uncertainties. These uncertainties propagate (in our calculations using the Euclidean distance formula) to the values of light and mass centeroid offsets. We then use normal distributions having the calculated (uncertainties propagated) means and uncertainties (standard deviations) to sample from and calculate the Pearson correlation cofficient (PCC) between the centeroid offsets and the $\\Sigma_{10, \\rm flux\\ selected}$ values. By sampling multiple times and calculating the PCCs we get a population of PCC values and thus calculate the mean, $1\\sigma$ upper and $1\\sigma$ lower uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant formulae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the case of $f = aA + bB$, where A and B are two random variables and a, b are constants, we have $$\\sigma_{f} = \\sqrt{a^{2}\\sigma_{A}^2 + b^{2}\\sigma_{B}^2 - 2ab\\sigma_{AB}}$$\n",
    "In the case of independent A, B ($\\sigma_{AB}=0$) and $a=b=1$ we have $$\\sigma_{f} = \\sqrt{\\sigma_{A}^2 + \\sigma_{B}^2}$$\n",
    "We also have for independent A, B ($\\sigma_{AB}=0$) and $f = \\sqrt{A^{2}+B^{2}}$,\n",
    "$$\\sigma_{f} \\approx \\sqrt{\\left(\\frac{A}{f}\\right)^{2}\\sigma_{A}^{2} + \\left(\\frac{B}{f}\\right)^{2}\\sigma_{B}^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from numpy.random import normal\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of the model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_names = [\n",
    "    \"DESIJ1018-0121\",\n",
    "    \"DESIJ1205+4110\",\n",
    "    \"DESIJ1624+0129\",\n",
    "    \"DESIJ0201-2739\" \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lens = len(lens_names)\n",
    "\n",
    "data_points = []  # list dictionaries with the parameter values\n",
    "center_diffs = []  # mean offsets between the light and mass centers\n",
    "sigma_center_diffs = []  # uncertainty propagated standard deviation of the center offsets\n",
    "size = 100  # population size\n",
    "samples_Pearson = []  # calculated PCC values\n",
    "\n",
    "for i in range(num_lens):\n",
    "    lens_name = lens_names[i]\n",
    "\n",
    "    output_path = f\"../lens_systems/{lens_name}/{lens_name}_point_estimates.yml\"\n",
    "\n",
    "    try:\n",
    "        with open(output_path, \"r\") as f:\n",
    "            data = yaml.full_load(f)\n",
    "\n",
    "    except AttributeError:\n",
    "        print(f\"Failed to load {lens_name}\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    output = {\n",
    "    'center_x_light': data.get('center_x_light'),\n",
    "    'center_x_mass': data.get('center_x_mass'),\n",
    "    'center_y_light': data.get('center_y_light'),\n",
    "    'center_y_mass': data.get('center_y_mass'),\n",
    "    'Sigma_10': data.get('Sigma_10'),\n",
    "    'Sigma_10_flux_selected': data.get('Sigma_10_flux_selected'),\n",
    "    'Sigma_20': data.get('Sigma_20'),\n",
    "    'Sigma_20_flux_selected': data.get('Sigma_20_flux_selected')\n",
    "    }\n",
    "\n",
    "    data_points.append(output)\n",
    "\n",
    "\n",
    "    x_diff = abs(data_points[i]['center_x_light'][0] - data_points[i]['center_x_mass'][0])\n",
    "    y_diff = abs(data_points[i]['center_y_light'][0] - data_points[i]['center_y_mass'][0])\n",
    "    center_diff = (x_diff**2 + y_diff**2)**0.5\n",
    "    center_diffs.append(center_diff)\n",
    "\n",
    "    sigma_x_light = mean([data_points[i]['center_x_light'][1], data_points[i]['center_x_light'][2]])\n",
    "    sigma_x_mass = mean([data_points[i]['center_x_mass'][1], data_points[i]['center_x_mass'][2]])\n",
    "    sigma_y_light = mean([data_points[i]['center_y_light'][1], data_points[i]['center_y_light'][2]])\n",
    "    sigma_y_mass = mean([data_points[i]['center_y_mass'][1], data_points[i]['center_y_mass'][2]])\n",
    "\n",
    "    sigma_x_diff = (sigma_x_light**2 + sigma_x_mass**2)**0.5\n",
    "    sigma_y_diff = (sigma_y_light**2 + sigma_y_mass**2)**0.5\n",
    "\n",
    "    sigma_center_diff = (((x_diff / center_diff)**2)*sigma_x_diff**2 + ((y_diff / center_diff)**2)*sigma_y_diff**2)**0.5\n",
    "    sigma_center_diffs.append(sigma_center_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Pearson correlation coefficient (PCC) calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coeffient:\n",
      "median:-0.7429244339502291\n",
      "upper uncertainty:0.12306411491740654\n",
      "lower uncertainty:0.0964965385299903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(size):\n",
    "    samples_delta_center = []\n",
    "    samples_Sigma_10 = []\n",
    "    for j in range(num_lens):\n",
    "        samples_delta_center.append(normal(center_diffs[j], sigma_center_diffs[j]))\n",
    "        samples_Sigma_10.append(data_points[j]['Sigma_10'])\n",
    "    \n",
    "    samples_Pearson.append(pearsonr(samples_delta_center, samples_Sigma_10))\n",
    "\n",
    "\n",
    "# print(data_points)\n",
    "# print(samples_Pearson)\n",
    "\n",
    "samples_Pearson_arr = np.array([k.statistic for k in samples_Pearson])\n",
    "Pearson_median = np.median(samples_Pearson_arr)\n",
    "Pearson_lower = np.percentile(samples_Pearson_arr, 16.0)\n",
    "Pearson_upper = np.percentile(samples_Pearson_arr, 84.0)\n",
    "\n",
    "print(f\"Pearson Correlation Coeffient:\\n\\\n",
    "median:{Pearson_median}\\n\\\n",
    "upper uncertainty:{Pearson_upper - Pearson_median}\\n\\\n",
    "lower uncertainty:{Pearson_median - Pearson_lower}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
